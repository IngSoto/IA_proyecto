# --------------------------------------------------------------------------------
# VARIABLES DE USO GENERAL
# --------------------------------------------------------------------------------

info_tipoUsuario = '''
## ¬øQu√© tipo de usuario eres?
'''


# --------------------------------------------------------------------------------
# VARIABLES PARA EL ALGORITMO REGLAS DE ASOCIACI√ìN
# --------------------------------------------------------------------------------

info_reglas_asociacion = '''
Las reglas de asociaci√≥n encuentran relaciones interesantes entre grandes conjuntos de elementos de datos. Esta regla muestra la frecuencia con la que se produce un conjunto de elementos en una transacci√≥n. Un ejemplo t√≠pico es el an√°lisis basado en el mercado.

El an√°lisis basado en el mercado es una de las t√©cnicas clave que se utilizan para mostrar asociaciones entre elementos. Permite a los minoristas identificar las relaciones entre los art√≠culos que las personas compran juntas con frecuencia.

Dado un conjunto de transacciones, podemos encontrar reglas que predecir√°n la ocurrencia de un art√≠culo en funci√≥n de las ocurrencias de otros art√≠culos en la transacci√≥n.
'''

info_visualizar_datafile = '''
1) NaN indica que ese elemento no fue adquirido en esa transacci√≥n.
'''

info_procesar = '''
Antes de ejecutar el algoritmo es recomendable observar la distribuci√≥n de la frecuencia de los elementos.
'''

info_implementar = '''
Para grandes conjuntos de datos, puede haber cientos de elementos en cientos de miles de transacciones. El algoritmo Apriori intenta extraer reglas para cada combinaci√≥n posible de elementos. 
'''

info_soporte = '''
El soporte se refiere a la popularidad predeterminada de un art√≠culo y se puede calcular encontrando el n√∫mero de transacciones que contienen un art√≠culo en particular dividido por el n√∫mero total de transacciones. 
'''

info_confianza = '''
La confianza se refiere a la probabilidad de que tambi√©n se compre un art√≠culo B si se compra el art√≠culo A. Se puede calcular encontrando el n√∫mero de transacciones en las que A y B se compran juntos, dividido por el n√∫mero total de transacciones en las que se compra A.
'''

info_elevacion = '''
La elevaci√≥n indica el nivel de relaci√≥n (aumento de probabilidad) entre el antecedente y consecuente de la regla. La elevaci√≥n (A -> B) se puede calcular dividiendo la confianza(A -> B) dividido por el soporte(B)
'''

# --------------------------------------------------------------------------------
# VARIABLES PARA EL ALGORITMO DE M√âTRICAS DE DISTANCIA
# --------------------------------------------------------------------------------

info_metricas_distancia = '''
Las m√©tricas de distancia son una parte clave de varios algoritmos de aprendizaje autom√°tico. Estas m√©tricas de distancia se utilizan tanto en el aprendizaje supervisado como no supervisado, generalmente para calcular la similitud entre puntos de datos.

Una m√©trica de distancia efectiva mejora el rendimiento de nuestro modelo de aprendizaje autom√°tico, ya sea para tareas de clasificaci√≥n o agrupaci√≥n.
'''

info_distancias = '''
## ¬øQu√© distancia te gustar√≠a calcular?
#### 1. Distancia Euclidiana.
Es una medida de distancia entre un par de muestras p y q en un espacio de caracter√≠sticas n-dimensional.
#### 2. Distancia de Chebyshev. 
Es el valor m√°ximo absoluto de las diferencias entre las coordenadas de un par de elementos.
#### 3. Distancia de Manhattan.
Calcula la distancia entre dos puntos en una ruta similar a una cuadr√≠cula (informaci√≥n geoespacial).
#### 4. Distancia de Minkowsky.
Es una distancia entre dos puntos en un espacio n-dimensional. Es una m√©trica de distancia generalizada: Euclidiana, Manhattan y Chebyshev.
'''

info_estandarizacion = '''
#### Recuerda, expertoüòé:
Las distancias dependen en gran medida del n√∫mero de constructos y del rango de clasificaci√≥n. Para poder comparar distancias entre cuadr√≠culas de diferente tama√±o y rango de clasificaci√≥n, es deseable una estandarizaci√≥n.

La estandarizaci√≥n de un conjunto de datos es un requisito com√∫n para muchos estimadores de aprendizaje autom√°tico, ya que pueden comportarse mal si las caracter√≠sticas individuales no se ven m√°s o menos como datos est√°ndar distribuidos normalmente. 

Si una caracter√≠stica tiene una varianza que es √≥rdenes de magnitud mayor que otras, podr√≠a dominar la funci√≥n objetivo y hacer que el estimador no pueda aprender de otras caracter√≠sticas correctamente como se esperaba. 
'''


info_parametrop = '''
Asimismo, toma en consideraci√≥n que para la distancia Minkowski se debe a√±adir un par√°metro llamado p, el cual corresponde al par√°metro lambda, que es el orden para calcular la distancia de tres formas diferentes
	Œª = 1, distancia de Manhattan.
	Œª = 2, distancia Euclidiana.
	Œª = 3, distancia de Chebyshev.
Dependiendo del valor insertado, proporcionar√° una aproximaci√≥n curvil√≠nea diferente.
'''

# --------------------------------------------------------------------------------
# VARIABLES PARA CLUSTERING JER√ÅRQUICO
# --------------------------------------------------------------------------------

info_cluster = '''
La agrupaci√≥n en cl√∫steres es una t√©cnica de aprendizaje autom√°tico cuyo objetivo es agrupar los puntos de datos que tienen propiedades y/o caracter√≠sticas similares, mientras que los puntos de datos en diferentes grupos deben tener propiedades y/o caracter√≠sticas muy poco convencionales.

El clustering es muy importante ya que determina la agrupaci√≥n intr√≠nseca entre los datos no etiquetados presentes. No hay criterios para una buena agrupaci√≥n. Depende del usuario, cu√°l es el criterio que puede utilizar para satisfacer su necesidad. 
'''

info_matriz_correlacion = '''
Una matriz de correlaci√≥n es una tabla que muestra los coeficientes de correlaci√≥n para diferentes variables. La matriz muestra la correlaci√≥n entre todos los posibles pares de valores en una tabla. Es una herramienta poderosa para resumir un gran conjunto de datos e identificar y visualizar patrones en los datos dados.
'''

info_mapa_calor = '''
Un mapa de calor es una representaci√≥n gr√°fica de datos donde cada valor de una matriz se representa como un color.
'''

info_clustering_jerarquico = '''
El agrupamiento jer√°rquico, tambi√©n conocido como an√°lisis de agrupamiento jer√°rquico, es un algoritmo que agrupa objetos similares en grupos llamados agrupamientos. El punto final es un conjunto de cl√∫steres, donde cada cl√∫ster es distinto de los dem√°s y los objetos dentro de cada cl√∫ster son muy similares entre s√≠.
'''


info_dendograma = '''
Un dendrograma es un diagrama que muestra la relaci√≥n jer√°rquica entre objetos. Por lo general, se crea como resultado de la agrupaci√≥n jer√°rquica. El uso principal de un dendrograma es encontrar la mejor manera de asignar objetos a grupos.
'''

info_cluter_registro = '''
Estos cl√∫sters formados agrupan a todos aquellos datos con mayor relaci√≥n, tomando como base la
matriz estandarizada de los datos.
'''

info_centroides = '''
De cada cl√∫ster se obtiene el promedio de los valores que tienen sus registros respecto a las variables consideradas
para el proceso de clusterizaci√≥n. Con base en estos centroides, es posible que un especialista genera las respectivas conclusiones.
'''

# --------------------------------------------------------------------------------
# VARIABLES PARA CLUSTERING PARTICIONAL
# --------------------------------------------------------------------------------

info_clustering_particional= '''
La agrupaci√≥n en cl√∫steres particional (o agrupaci√≥n en cl√∫steres de particiones) son m√©todos de agrupaci√≥n que se utilizan para clasificar las observaciones, dentro de un conjunto de datos, en varios grupos en funci√≥n de su similitud. 

El algoritmo k-means es un m√©todo de agrupamiento que divide un conjunto de n observaciones en k grupos distintos gracias a valores medios. Pertenece al √°mbito de los algoritmos no supervisados, ya que las n observaciones no cuentan con una etiqueta que nos diga de qu√© grupo es cada dato, siendo los datos agrupados seg√∫n sus propiedades o caracter√≠sticas.
'''

info_metodo_codo = '''
La idea b√°sica de los algoritmos de clustering es la minimizaci√≥n de la varianza intra-cluster y la maximizaci√≥n de la varianza inter-cluster. Es decir, queremos que cada observaci√≥n se encuentre muy cerca a las de su mismo grupo y los grupos lo m√°s lejos posible entre ellos.

El m√©todo del codo utiliza la distancia media de las observaciones a su centroide. Es decir, se fija en las distancias intra-cluster. Cuanto m√°s grande es el n√∫mero de clusters k, la varianza intra-cluster tiende a disminuir. Cuanto menor es la distancia intra-cluster mejor, ya que significa que los cl√∫sters son m√°s compactos. El m√©todo del codo busca el valor k que satisfaga que un incremento de k, no mejore sustancialmente la distancia media intra-cluster.
'''
# --------------------------------------------------------------------------------
# VARIABLES PARA REGRESI√ìN LOG√çSTICA
# --------------------------------------------------------------------------------

info_regresion_logistia = '''
La regresi√≥n log√≠stica resulta √∫til para los casos en los que se desea predecir la presencia o ausencia de una caracter√≠stica o resultado seg√∫n los valores de un conjunto de predictores. Es similar a un modelo de regresi√≥n lineal pero est√° adaptado para modelos en los que la variable dependiente es dicot√≥mica. Los coeficientes de regresi√≥n log√≠stica pueden utilizarse para estimar la raz√≥n de probabilidad de cada variable independiente del modelo. La regresi√≥n log√≠stica se puede aplicar a un rango m√°s amplio de situaciones de investigaci√≥n que el an√°lisis discriminante.
'''


info_vars_predictoras = '''
Las variables predictoras representar√°n al conjunto de las X, que son las variables independientes de nuestro modelo.
'''

info_vars_apronosticar = '''
Las variables a pronosticar representar√°n al conjunto de las Y, que son las variables dependientes de nuestro modelo.
'''

info_matriz_confusion = '''
La matriz de confusi√≥n muestra el n√∫mero de clases pronosticadas y el n√∫mero de clasificaciones correctas.
'''

# --------------------------------------------------------------------------------
# VARIABLES PARA √ÄRBOL DE REGRESI√ìN
# --------------------------------------------------------------------------------

info_arbol_regresion = '''
La regresi√≥n del √°rbol de decisi√≥n observa las caracter√≠sticas de un objeto y entrena un modelo en la estructura de un √°rbol para predecir datos en el futuro.
'''

info_max_depth = '''
max_depth se refiere a la profundidad m√°xima hasta la cual llegar√° el √°rbol. Por defecto se tiene el m√°ximo
de profundidad posible.
'''

info_min_samples_split = '''
min_samples_split se refiere a la cantidad m√≠nima de resultados que deben de existir para que se realice una divisi√≥n en las
muestras. Por defecto se tiene un valor de 2.
'''

info_min_samples_leaf = '''
min_samples_leaf la cantidad m√≠nima de elementos que debe de haber en cada nodo hoja del √°rbol. Por defecto se tiene un valor de 1.
'''

info_importancia = '''
Se presentan el nombre de la variable y su respectivo valor de importancia.
'''

info_arbol_grafica = '''
√Årbol con los respectivos nombres de las variables. Se muestra cada uno de los nodos que conforman al √°rbol, con
el respectivo criterio o regla, error cuadr√°tico, n√∫mero de elementos que lo conforman y el valor promedio.
'''
# --------------------------------------------------------------------------------
# QUOTES
# --------------------------------------------------------------------------------

quote1 = '''
La clave de la inteligencia artificial siempre ha sido la representaci√≥n. ‚Äì Jeff Hawkins
'''

quote2 = '''
Visualizo una √©poca en la que (los humanos) seremos a los robots lo que los perros son para nosotros. ‚Äì Claude Shannon
'''

quote3 = '''
Estamos en un coche yendo hacia el futuro utilizando s√≥lo nuestro espejo retrovisor. ‚Äì Herbert Marshall Mcluhan
'''
quote4 = '''
Habr√° seres humanos con minirrobots en el cerebro. ‚Äì Raymond Kurzweil
'''
quote5 = '''
Las m√°quinas son objetos, que han sido construidos para vencer la resistencia del mundo, resistencia con la que choca el trabajo. ‚Äì Vil√©m Flusser
'''

# --------------------------------------------------------------------------------
# SOBRE ALGORTHMIA
# --------------------------------------------------------------------------------

info_algorithmia = '''
El nombre ALGORITHMIA es un juego de palabras que combina ALGORITHM (de algoritmo) y IA (de Inteligencia Artificial). En este entorno puedes escoger diferentes algoritmos que te permitir√°n examinar, estudiar y aplicar distintos algoritmos de Inteligencia Artificial. Entre ellos est√°n: Reglas de Asociaci√≥n, M√©tricas de distancia, Clusteirng, Regresi√≥n Log√≠stica y √Årboles de Decisi√≥n. 
'''




















